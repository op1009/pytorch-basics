{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Basics"
      ],
      "metadata": {
        "id": "75qiWcfJb0B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different types of tensors"
      ],
      "metadata": {
        "id": "FD64MWrXb7kQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTyJkjkKWyHC",
        "outputId": "fc4a933b-780e-44cc-dd53-42a68c205ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empty(1):  tensor([5.1611e-06])\n",
            "empty(3):  tensor([2.9112e-20, 3.2111e-41, 0.0000e+00])\n",
            "empty(2,3):  tensor([[5.1611e-06, 4.4074e-41, 5.1611e-06],\n",
            "        [4.4074e-41, 4.4842e-44, 0.0000e+00]])\n",
            "empty(2, 2, 3):  tensor([[[-2.2829e-34,  3.2115e-41, -2.7622e-34],\n",
            "         [ 3.2115e-41,  4.4842e-44,  0.0000e+00]],\n",
            "\n",
            "        [[ 8.9683e-44,  0.0000e+00,  8.2908e-20],\n",
            "         [ 3.2111e-41,  0.0000e+00,  2.3510e-38]]])\n",
            "empty(2, 2, 3, 4):  tensor([[[[ 5.1612e-06,  4.4074e-41,  5.1612e-06,  4.4074e-41],\n",
            "          [ 3.2618e-17,  4.4074e-41,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  2.7972e-17,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00, -2.7622e-34,  3.2115e-41],\n",
            "          [ 2.8408e-06,  4.4074e-41,  3.0556e-06,  4.4074e-41]]]])\n",
            "rand(5,3):  tensor([[0.4376, 0.5087, 0.3681],\n",
            "        [0.8475, 0.9902, 0.2778],\n",
            "        [0.7407, 0.7478, 0.5676],\n",
            "        [0.1810, 0.2084, 0.7965],\n",
            "        [0.4981, 0.6940, 0.0772]])\n",
            "zeros(3, 4):  tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "ones(3, 4):  tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# uninitialized\n",
        "# scalar\n",
        "x = torch.empty(1)\n",
        "print(\"empty(1): \", x)\n",
        "\n",
        "# vector\n",
        "x = torch.empty(3)\n",
        "print(\"empty(3): \", x)\n",
        "\n",
        "# matrix\n",
        "x = torch.empty(2, 3)\n",
        "print(\"empty(2,3): \", x)\n",
        "\n",
        "# 3 dimensional tensor\n",
        "x = torch.empty(2, 2, 3)\n",
        "print(\"empty(2, 2, 3): \", x)\n",
        "\n",
        "# 4 dimensional tensor\n",
        "x = torch.empty(2, 2, 3, 4)\n",
        "print(\"empty(2, 2, 3, 4): \", x)\n",
        "\n",
        "# initialise randomly\n",
        "r = torch.rand(5, 3)\n",
        "print(\"rand(5,3): \", r)\n",
        "\n",
        "# zero filled\n",
        "z = torch.zeros(3, 4)\n",
        "print(\"zeros(3, 4): \", z)\n",
        "\n",
        "# one filled\n",
        "z = torch.ones(3, 4)\n",
        "print(\"ones(3, 4): \", z)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check size\n",
        "print(\"size(): \", z.size())  # function\n",
        "print(\"size(0): \", z.size(0))\n",
        "\n",
        "print(\"shape: \", z.shape)  # attribute\n",
        "print(\"shape[0]: \", z.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t8Ow52VZt85",
        "outputId": "22c0ff4f-7b67-4dd2-b294-c76af8de9bb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size():  torch.Size([3, 4])\n",
            "size(0):  3\n",
            "shape:  torch.Size([3, 4])\n",
            "shape[0]:  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, default float32\n",
        "x = torch.rand(4, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq5D7PoTaW03",
        "outputId": "7a0ca2af-541c-4928-8b63-50e833ba51af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor([[0.1470, 0.6235, 0.5991],\n",
            "        [0.4111, 0.1787, 0.8418],\n",
            "        [0.1372, 0.4185, 0.1890],\n",
            "        [0.1650, 0.4082, 0.9995]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct tensor from data\n",
        "x = torch.tensor([5.5, 3, 1])\n",
        "print(x, x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuoMKpEZbVqw",
        "outputId": "da3cb981-bb23-4304-98e2-941b8d9911e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000, 1.0000]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires grad arg\n",
        "# False by dafault, this tells pytorch that this tensor will be required to compute gradient later\n",
        "# i.e this is a variable in model that will be optimized later\n",
        "x = torch.tensor([5, 4, 5.0, 8], requires_grad = True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZXecE9RbqsH",
        "outputId": "ecc22220-73dd-4b33-8d85-0e4d78b8ee0c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 4., 5., 8.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arithmetic operation of tensors"
      ],
      "metadata": {
        "id": "ZolivDTZcUH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 3)\n",
        "y = torch.rand(2, 3)\n",
        "\n",
        "# elementwise\n",
        "s = x+y\n",
        "print(s)\n",
        "\n",
        "s = torch.add(x, y)\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuZrVxwEgMDn",
        "outputId": "5587c9ed-1599-4c28-ebf4-2b3ea750cf5e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.1778, 1.9540, 1.3053],\n",
            "        [1.0840, 1.3519, 1.0847]])\n",
            "tensor([[1.1778, 1.9540, 1.3053],\n",
            "        [1.0840, 1.3519, 1.0847]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in place addition, everything with a trailing underscore is an inplace operation\n",
        "# i.e it will modify te variable\n",
        "print(y)\n",
        "\n",
        "s = y + x\n",
        "print(s)\n",
        "\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFHPOzQ5hTX_",
        "outputId": "b3de2281-86f7-4be1-c4fe-7541ba5ca0c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1778, 0.9540, 0.3053],\n",
            "        [0.0840, 0.3519, 0.0847]])\n",
            "tensor([[1.1778, 1.9540, 1.3053],\n",
            "        [1.0840, 1.3519, 1.0847]])\n",
            "tensor([[1.1778, 1.9540, 1.3053],\n",
            "        [1.0840, 1.3519, 1.0847]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subtraction\n",
        "z = x - y\n",
        "\n",
        "# multiplication\n",
        "m = x * y\n",
        "mm = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "d = x / y\n",
        "dd = torch.div(x, y)"
      ],
      "metadata": {
        "id": "HDGLuLQ3h04U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# slicing\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(\"x[:, 0]\", x[:, 0])\n",
        "print(\"x[:, 1]\", x[:, 1])\n",
        "print(\"x[:, 2]\", x[:, 2])\n",
        "\n",
        "print(\"x[0, :]\", x[0, :])\n",
        "\n",
        "print(\"x[0, 0].item()\", x[0, 0].item())  # only for scalers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEXflij-iwBF",
        "outputId": "327cf177-da50-4ef3-858f-ad62dc1d19cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3319, 0.7285, 0.8806],\n",
            "        [0.8677, 0.6126, 0.7850],\n",
            "        [0.9919, 0.5969, 0.1650],\n",
            "        [0.3013, 0.3135, 0.1380],\n",
            "        [0.8149, 0.5411, 0.4005]])\n",
            "x[:, 0] tensor([0.3319, 0.8677, 0.9919, 0.3013, 0.8149])\n",
            "x[:, 1] tensor([0.7285, 0.6126, 0.5969, 0.3135, 0.5411])\n",
            "x[:, 2] tensor([0.8806, 0.7850, 0.1650, 0.1380, 0.4005])\n",
            "x[0, :] tensor([0.3319, 0.7285, 0.8806])\n",
            "x[0, 0].item() 0.3319409489631653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(4, 4)  # normal distribution\n",
        "print(x)\n",
        "y = x.view(16) # reshape\n",
        "print(y)\n",
        "\n",
        "# -1 dimension implies, infer from te input to et required shape\n",
        "z= x.view(-1, 8)\n",
        "print(x.shape, y.shape, z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qebc66djkGu",
        "outputId": "16fba91a-b18c-484d-b626-f5a86736013a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4251,  0.0549, -1.4495, -0.6712],\n",
            "        [ 0.4987,  1.1041, -0.0975, -1.1447],\n",
            "        [-0.1572,  1.3294, -2.1893, -0.8384],\n",
            "        [ 0.1376,  0.1588, -0.5424, -2.2434]])\n",
            "tensor([ 0.4251,  0.0549, -1.4495, -0.6712,  0.4987,  1.1041, -0.0975, -1.1447,\n",
            "        -0.1572,  1.3294, -2.1893, -0.8384,  0.1376,  0.1588, -0.5424, -2.2434])\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting a torch tensor to numpy array and vice versa\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "print(a.dtype)\n",
        "\n",
        "# torch to numpy\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(b.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E49KXE3Dlcqk",
        "outputId": "1b044fe7-1c7f-4619-a4fc-2202b8afc4c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "torch.float32\n",
            "[1. 1. 1. 1. 1.]\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caution: If the tensor is on CPU, both will share same memory location\n",
        "# i.e. changing one will change other\n",
        "a.add_(3)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmSL3KXMmPCH",
        "outputId": "6c51ec3a-d5f1-436d-efbd-ead3e0a8fc71"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 4., 4., 4., 4.])\n",
            "[4. 4. 4. 4. 4.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy to torch\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "\n",
        "# same memory location\n",
        "b = torch.from_numpy(a)\n",
        "\n",
        "# new memory\n",
        "c = torch.tensor(a)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu-a4CYxnIoy",
        "outputId": "704ea9d7-68cb-4594-a9e5-543f5c30fdee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU support\n",
        "- By default all tensors are created on CPU. But we can also move them to GPU(if vailable), or create them directly on the GPU"
      ],
      "metadata": {
        "id": "dK-Vh_FtfuxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWsJzdgtoZGX",
        "outputId": "817f7b7b-48d1-4858-f77e-e6b66418022d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move tensors to device\n",
        "x = torch.rand(2, 2).to(device)\n",
        "\n",
        "x = x.to('cpu')\n",
        "# x = x.to('cuda:0')\n",
        "\n",
        "# create directly on device, more efficient\n",
        "x = torch.rand(2, 2, device=device)"
      ],
      "metadata": {
        "id": "1XZBZMNhpHnx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autograd\n",
        "- Autograd package provides automatic differentiation for all operations on Tensors. Generally speaking torch.autograd is an engine for computing the vector-Jacobian product. It computes partial derivatives while applying the chain rule.\n",
        "\n",
        "- Set `requires_grad = True`. This tracks all the ops on the tensor\n"
      ],
      "metadata": {
        "id": "2HeeRAAvp-DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_in attrib.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x)\n",
        "print(y)\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icAtiKYFqEPb",
        "outputId": "bcfc8dac-2a13-41ec-d54e-aa5ba74d4f08"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.4129, -0.0946, -0.5641], requires_grad=True)\n",
            "tensor([0.5871, 1.9054, 1.4359], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7adb3c21d540>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do more ops\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "\n",
        "z = z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXc7ve6XtCDy",
        "outputId": "b598594a-449f-4ac6-949f-8674d809de2d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.0340, 10.8917,  6.1855], grad_fn=<MulBackward0>)\n",
            "tensor(6.0371, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute gradient with backprop\n",
        "# when we finish our computation, we can call .backward() and have all gradients computed automatically\n",
        "# Gradient for this tensor will be accumulated into .grad attribute.\n",
        "# It is the partial derivative of the function w.r.t. the tensor\n",
        "\n",
        "print(x.grad)\n",
        "z.backward()\n",
        "print(x.grad)  # dz/dx\n",
        "\n",
        "# Caution: backward() accumulates the gradient for this tensor into .grad attribute\n",
        "# so in training pipeline, be careful during optimization, optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXvW3vsHtSSM",
        "outputId": "4f6111c9-c0cb-4d7f-bd17-830f6ee465dc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([1.1742, 3.8108, 2.8718])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stop tensor from tracking history\n",
        "For example during training loop when we want to update our weights, or after training during evaluation. These ops shouldn't be part of the gradient computation, to prevent this we can use:\n",
        "- `x.requires_grad_(False)`\n",
        "- `x.detach()`\n",
        "- wrap in `with torch.no_grad():`\n",
        "-"
      ],
      "metadata": {
        "id": "Sl0_hNTdvnZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "a = torch.randn(2, 3)\n",
        "b = (a * a).sum()\n",
        "\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)\n",
        "\n",
        "a = torch.randn(2, 3, requires_grad=True)\n",
        "b = (a * a).sum()\n",
        "\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDG_qZlkulYx",
        "outputId": "1061c599-ac27-452f-aa18-16dfd1f3a339"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7adb3c21e6e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2, 3, requires_grad=True)\n",
        "b = a.detach()\n",
        "\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnOjmqO4xQn_",
        "outputId": "fb5f128a-c176-4d0d-8de3-d70b566a8ad4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2, 3, requires_grad=True)\n",
        "with torch.no_grad():\n",
        "  b = a**2\n",
        "  print(a.requires_grad)\n",
        "  print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3d-6ssAydKh",
        "outputId": "de2e7dfc-f898-4272-d29f-1ab07591c200"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Descent"
      ],
      "metadata": {
        "id": "4EMWVJ06y-te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "# f = w*x + b\n",
        "# here f = 2 *x\n",
        "\n",
        "x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8], dtype=torch.float32)\n",
        "y = torch.tensor([2, 4, 6, 8, 10, 12, 14, 16], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# moodel output\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y)**2).mean()\n",
        "\n",
        "x_test = 5.0\n",
        "\n",
        "print(f\"Pred before training: f({x_test}) = {forward(x_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg1R07tky2Es",
        "outputId": "813db48c-ddc6-4f2b-ca8f-06cfcc0d79b1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred before training: f(5.0) = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  y_pred = forward(x)\n",
        "\n",
        "  # loss\n",
        "  l = loss(y, y_pred)\n",
        "\n",
        "  # calc gradient = backward pass\n",
        "  l.backward()\n",
        "\n",
        "  # update weights\n",
        "  # w.data = w.data - lr * w.grad\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "\n",
        "\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f\"epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.3f}\")\n",
        "\n",
        "print(f\"Pred after training: f({x_test}) = {forward(x_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yfPNTaQ5S9C",
        "outputId": "8669c640-01d8-411f-f43f-24a496e40807"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: w = 1.998, loss = 0.000\n",
            "epoch 20: w = 2.000, loss = 0.000\n",
            "epoch 30: w = 2.000, loss = 0.000\n",
            "epoch 40: w = 2.000, loss = 0.000\n",
            "epoch 50: w = 2.000, loss = 0.000\n",
            "epoch 60: w = 2.000, loss = 0.000\n",
            "epoch 70: w = 2.000, loss = 0.000\n",
            "epoch 80: w = 2.000, loss = 0.000\n",
            "epoch 90: w = 2.000, loss = 0.000\n",
            "epoch 100: w = 2.000, loss = 0.000\n",
            "Pred after training: f(5.0) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model, Loss and Optimizer\n",
        "A typical PyTorch pipeline looks like:\n",
        "1. Design model(input, output, forward passwith different layers)\n",
        "2. Construct loss and optimizer\n",
        "3. Training loop:\n",
        "  - Forward : compute prediction and loss\n",
        "  - Backward: compute gradient\n",
        "  - Update weights\n",
        "  "
      ],
      "metadata": {
        "id": "6vdX1TfeUi0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear Regression\n",
        "# f = w * x\n",
        "# here: f = 2 * x\n",
        "\n",
        "# 0. Data preparation, Training sample\n",
        "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype = torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8], [10], [12], [14], [16]], dtype = torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'n_samples = {n_samples}, n_features = {n_features}')\n",
        "\n",
        "# create a test sample\n",
        "X_test = torch.tensor([5], dtype = torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc4QC26e7bkB",
        "outputId": "aa995e3f-d408-4a38-ea01-9c4e0151967d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples = 8, n_features = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Design model, the model has to implement forward pass\n",
        "\n",
        "# 1. Define Model\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "\n",
        "    # define different layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "input_size, output_size = n_features, n_features\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f\"Pred before training: f({X_test}) = {model(X_test).item():.3f}\")\n",
        "\n",
        "# 2. Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_epochs= 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# 3. Training Loop\n",
        "for epoch in range(n_epochs):\n",
        "  # forward pass, forward function from model will be called\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(y_pred, Y)\n",
        "\n",
        "  # backward pass\n",
        "  l.backward()\n",
        "\n",
        "  # update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero the gradients after updating\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    w, b = model.parameters()   # unpack params\n",
        "    print(f'epoch {epoch+1} : w = {w[0][0].item()}, loss = {l.item()}')\n",
        "\n",
        "\n",
        "print(f\"Pred after training: f({X_test}) = {model(X_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Su1_6s7u6_",
        "outputId": "1ebd4514-a969-4641-c5fe-804f57f3c43d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred before training: f(tensor([5.])) = -1.563\n",
            "epoch 10 : w = 1.8202273845672607, loss = 0.20923356711864471\n",
            "epoch 20 : w = 1.8285167217254639, loss = 0.19295983016490936\n",
            "epoch 30 : w = 1.8352419137954712, loss = 0.17812317609786987\n",
            "epoch 40 : w = 1.8417026996612549, loss = 0.16442739963531494\n",
            "epoch 50 : w = 1.8479101657867432, loss = 0.15178456902503967\n",
            "epoch 60 : w = 1.8538740873336792, loss = 0.1401139795780182\n",
            "epoch 70 : w = 1.8596042394638062, loss = 0.12934064865112305\n",
            "epoch 80 : w = 1.8651096820831299, loss = 0.1193956732749939\n",
            "epoch 90 : w = 1.8703992366790771, loss = 0.11021538823843002\n",
            "epoch 100 : w = 1.875481367111206, loss = 0.10174088925123215\n",
            "Pred after training: f(tensor([5.])) = 10.077\n"
          ]
        }
      ]
    }
  ]
}